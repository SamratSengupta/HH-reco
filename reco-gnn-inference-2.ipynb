{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5ea47c-b086-43b9-a20f-011137c7ec4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samra\\AppData\\Local\\Temp\\ipykernel_20980\\2725847578.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edges['PERSON_ID'] = edges['PERSON_ID'].map(person_id_map)\n",
      "C:\\Users\\samra\\AppData\\Local\\Temp\\ipykernel_20980\\2725847578.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edges['ProviderCode'] = edges['ProviderCode'].map(provider_id_map)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Load the interaction data\n",
    "data_path = 'metadata/'\n",
    "interaction_df = pd.read_csv(data_path + 'interactions.csv').drop('Unnamed: 0', axis=1)\n",
    "interaction_df = interaction_df.rename(columns={'FACILITYCODE': 'FacilityCode'})\n",
    "\n",
    "# Preprocess the interaction data\n",
    "# Preprocess the interaction data\n",
    "interaction_df['SurveyAnswerScore'] = np.round(interaction_df['SurveyAnswerScore'], 2)\n",
    "interaction_df['RecommendStar'] = np.round(interaction_df['RecommendStar'], 2)\n",
    "interaction_df = interaction_df.drop('InsertedOn', axis=1)\n",
    "\n",
    "# Aggregate the interaction data\n",
    "interaction_df_mod = interaction_df.groupby(['PERSON_ID', 'ProviderCode']).agg({\n",
    "    'SurveyAnswerScore': 'mean',\n",
    "    'RecommendStar': 'mean',\n",
    "    'num_visits': 'first',\n",
    "    'age': 'mean',\n",
    "    'ratings': 'mean',\n",
    "    'star_rating': 'first',\n",
    "    'survey_score': 'first',\n",
    "    'zip_code': 'first',\n",
    "    'GENDER_Female': 'first',\n",
    "    'GENDER_Male': 'first',\n",
    "    'FacilityCode': lambda x: list(x),\n",
    "    'SpecialtyCode': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "interaction_df_mod['visit_ratings'] = 0.65 * interaction_df_mod['ratings'] + 0.35 * interaction_df_mod['num_visits']\n",
    "\n",
    "# Generate unique integer mappings for FacilityCode and SpecialtyCode\n",
    "all_facility_codes = set(code for sublist in interaction_df_mod['FacilityCode'] for code in sublist)\n",
    "facility_code_map = {code: idx for idx, code in enumerate(all_facility_codes)}\n",
    "\n",
    "all_specialty_codes = set(code for sublist in interaction_df_mod['SpecialtyCode'] for code in sublist)\n",
    "specialty_code_map = {code: idx for idx, code in enumerate(all_specialty_codes)}\n",
    "\n",
    "interaction_df_mod['FacilityCode'] = interaction_df_mod['FacilityCode'].apply(lambda codes: [facility_code_map[code] for code in codes])\n",
    "interaction_df_mod['SpecialtyCode'] = interaction_df_mod['SpecialtyCode'].apply(lambda codes: [specialty_code_map[code] for code in codes])\n",
    "\n",
    "# Prepare provider features\n",
    "provider_features = interaction_df_mod.groupby('ProviderCode').agg({\n",
    "    'num_visits': 'sum',\n",
    "    'survey_score': 'mean',\n",
    "    'star_rating': 'mean',\n",
    "    'FacilityCode': lambda x: list(set([i for sublist in x for i in sublist])),\n",
    "    'SpecialtyCode': lambda x: list(set([i for sublist in x for i in sublist]))\n",
    "}).reset_index()\n",
    "\n",
    "# Prepare person features\n",
    "person_features = interaction_df_mod.groupby('PERSON_ID').agg({\n",
    "    'age': 'first',\n",
    "    'GENDER_Female': 'first',\n",
    "    'GENDER_Male': 'first',\n",
    "    'FacilityCode': lambda x: list(set([i for sublist in x for i in sublist])),\n",
    "    'SpecialtyCode': lambda x: list(set([i for sublist in x for i in sublist]))\n",
    "}).reset_index()\n",
    "\n",
    "# Prepare edge features\n",
    "edges = interaction_df_mod[['PERSON_ID', 'ProviderCode', 'visit_ratings']]\n",
    "\n",
    "# Map IDs to integers\n",
    "person_id_map = {id: idx for idx, id in enumerate(person_features['PERSON_ID'].unique())}\n",
    "provider_id_map = {id: idx + len(person_id_map) for idx, id in enumerate(provider_features['ProviderCode'].unique())}\n",
    "id_provider_map = {value: key for key, value in provider_id_map.items()}\n",
    "\n",
    "# Apply mapping to the edges\n",
    "edges['PERSON_ID'] = edges['PERSON_ID'].map(person_id_map)\n",
    "edges['ProviderCode'] = edges['ProviderCode'].map(provider_id_map)\n",
    "\n",
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add person nodes with features\n",
    "for _, row in person_features.iterrows():\n",
    "    G.add_node(person_id_map[row['PERSON_ID']], bipartite=0, age=row['age'], gender_female=row['GENDER_Female'], gender_male=row['GENDER_Male'], facility_codes=row['FacilityCode'], specialty_codes=row['SpecialtyCode'])\n",
    "\n",
    "# Add provider nodes with features\n",
    "for _, row in provider_features.iterrows():\n",
    "    G.add_node(provider_id_map[row['ProviderCode']], bipartite=1, num_visits=row['num_visits'], survey_score=row['survey_score'], star_rating=row['star_rating'], facility_codes=row['FacilityCode'], specialty_codes=row['SpecialtyCode'])\n",
    "\n",
    "# Add edges with features\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['PERSON_ID'], row['ProviderCode'], visit_ratings=row['visit_ratings'])\n",
    "\n",
    "# Convert to adjacency matrix\n",
    "adj_matrix = nx.to_numpy_array(G)\n",
    "adj_matrix = torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "\n",
    "# Extract node features for persons and providers\n",
    "person_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 0]\n",
    "provider_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 1]\n",
    "\n",
    "person_features_tensor = torch.tensor([\n",
    "    [d['age'], d['gender_female'], d['gender_male']] \n",
    "    for n, d in G.nodes(data=True) if n in person_nodes\n",
    "], dtype=torch.float32)\n",
    "\n",
    "provider_features_tensor = torch.tensor([\n",
    "    [d['num_visits'], d['survey_score'], d['star_rating']]\n",
    "    for n, d in G.nodes(data=True) if n in provider_nodes\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Create a single feature tensor\n",
    "all_features = torch.cat([person_features_tensor, provider_features_tensor], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cb21a6-4494-4689-9f15-492ced987c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.8, l2_reg=1e-5):\n",
    "        super(GNNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "    def forward(self, adjacency_matrix, feature_matrix):\n",
    "        h = torch.mm(adjacency_matrix, feature_matrix)\n",
    "        h = self.linear(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.batch_norm(h)\n",
    "        return F.relu(h)\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, num_facilities, num_specialties, in_features, hidden_features, out_features, embedding_dim=16, dropout=0.8, l2_reg=1e-5):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.facility_embedding = nn.Embedding(num_facilities, embedding_dim)\n",
    "        self.specialty_embedding = nn.Embedding(num_specialties, embedding_dim)\n",
    "        self.gnn1 = GNNLayer(in_features + 2 * embedding_dim, hidden_features, dropout, l2_reg)\n",
    "        self.gnn2 = GNNLayer(hidden_features, out_features, dropout, l2_reg)\n",
    "\n",
    "    def forward(self, adjacency_matrix, features, person_facility_codes, person_specialty_codes, provider_facility_codes, provider_specialty_codes):\n",
    "        # Generate embeddings for facility and specialty codes\n",
    "        person_facility_embeds = [torch.mean(self.facility_embedding(torch.tensor(codes)), dim=0) for codes in person_facility_codes]\n",
    "        person_specialty_embeds = [torch.mean(self.specialty_embedding(torch.tensor(codes)), dim=0) for codes in person_specialty_codes]\n",
    "        provider_facility_embeds = [torch.mean(self.facility_embedding(torch.tensor(codes)), dim=0) for codes in provider_facility_codes]\n",
    "        provider_specialty_embeds = [torch.mean(self.specialty_embedding(torch.tensor(codes)), dim=0) for codes in provider_specialty_codes]\n",
    "\n",
    "        # Concatenate embeddings with other features\n",
    "        person_embeds = torch.cat([torch.stack(person_facility_embeds), torch.stack(person_specialty_embeds)], dim=1)\n",
    "        provider_embeds = torch.cat([torch.stack(provider_facility_embeds), torch.stack(provider_specialty_embeds)], dim=1)\n",
    "\n",
    "        # Combine features with embeddings\n",
    "        person_features = torch.cat([features[:len(person_embeds)], person_embeds], dim=1)\n",
    "        provider_features = torch.cat([features[len(person_embeds):], provider_embeds], dim=1)\n",
    "\n",
    "        features = torch.cat([person_features, provider_features], dim=0)\n",
    "\n",
    "        # Apply GNN layers\n",
    "        h = self.gnn1(adjacency_matrix, features)\n",
    "        h = self.gnn2(adjacency_matrix, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98ecbf4-923b-4fa1-8b04-4ed868ff5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_facility_codes = [d['facility_codes'] for n, d in G.nodes(data=True) if n in person_nodes]\n",
    "person_specialty_codes = [d['specialty_codes'] for n, d in G.nodes(data=True) if n in person_nodes]\n",
    "provider_facility_codes = [d['facility_codes'] for n, d in G.nodes(data=True) if n in provider_nodes]\n",
    "provider_specialty_codes = [d['specialty_codes'] for n, d in G.nodes(data=True) if n in provider_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8231b951-a3f0-48a4-b34c-8705f25818a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_facilities = len(interaction_df['FacilityCode'].unique().tolist())\n",
    "num_specialties = len(interaction_df['SpecialtyCode'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e0c7ce-b785-431c-b981-dce5afefe39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = 3\n",
    "hidden_feats = 32\n",
    "out_feats = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1e11c1-520d-459e-8021-8acbf2e84cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNModel(\n",
       "  (facility_embedding): Embedding(53, 16)\n",
       "  (specialty_embedding): Embedding(89, 16)\n",
       "  (gnn1): GNNLayer(\n",
       "    (linear): Linear(in_features=35, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (gnn2): GNNLayer(\n",
       "    (linear): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "    (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_model = GNNModel(num_facilities, num_specialties,in_feats, hidden_feats, out_feats)\n",
    "gcn_model.load_state_dict(torch.load('models/gcn_reco_v2.pth'))\n",
    "gcn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "670df005-2e96-4954-91b0-a60875a11b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, user_id,features,selected_provider_lst, k=5):\n",
    "    # Get the node ID for the user\n",
    "    if user_id not in person_id_map:\n",
    "        return []\n",
    "        \n",
    "    user_node = person_id_map[user_id]    \n",
    "    # Get the logits (embeddings) for all nodes\n",
    "    with torch.no_grad():\n",
    "        logits = model(adj_matrix, features, person_facility_codes, person_specialty_codes, provider_facility_codes, provider_specialty_codes)\n",
    "    \n",
    "    # Get the embeddings for the user\n",
    "    user_embedding = logits[user_node]\n",
    "    \n",
    "    # Calculate the score for each provider\n",
    "    provider_scores = []\n",
    "    for provider_node in provider_nodes:\n",
    "        provider_embedding = logits[provider_node]\n",
    "        score = torch.dot(user_embedding, provider_embedding).item()        \n",
    "        # Filter based on zip code and specialty code if provided\n",
    "        provider_id = id_provider_map[provider_node]\n",
    "        provider_info = provider_features[provider_features['ProviderCode'] == provider_id].iloc[0]     \n",
    "        \n",
    "        provider_scores.append((provider_node, score))\n",
    "\n",
    "    \n",
    "    mapped_provider = []\n",
    "    for item_i,item_j in provider_scores:\n",
    "        if id_provider_map[item_i] in selected_provider_lst:\n",
    "            mapped_provider.append((item_i,item_j))\n",
    "            \n",
    "\n",
    "    # Sort the providers by score in descending order\n",
    "    provider_scores = sorted(mapped_provider, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top k providers\n",
    "    top_providers = [(id_provider_map[provider_node],score) for provider_node, score in provider_scores[:k]]\n",
    "    \n",
    "    return top_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25455365-17cb-4f37-b0f4-c04a46249dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '0071588ba3116840b32d9f7fcf3ce2707c5bbcc09a3960fbb5c91e1e7e8eb21d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1c0976-aefd-456c-acf4-11dd4eaa031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = 34950\n",
    "specialty_code = 'PS305'\n",
    "selected_provider_df = interaction_df[(interaction_df['zip_code']==zip_code)\n",
    "                                            & (interaction_df['SpecialtyCode']==specialty_code)]\n",
    "selected_provider_lst = selected_provider_df['ProviderCode'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e378d4d-171b-428b-a09d-66676a105964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for user 0071588ba3116840b32d9f7fcf3ce2707c5bbcc09a3960fbb5c91e1e7e8eb21d: [('2J7P4', 0.8380189538002014), ('XF6BG', 0.806585967540741), ('2RTCQ', 0.771134078502655)]\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_recommendations(gcn_model, user_id,all_features,selected_provider_lst, k=5)\n",
    "print(f\"Top recommendations for user {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8255732c-f569-4e0f-86f6-d72069ba3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_lst = [item[0] for item in recommendations]\n",
    "providers_df = interaction_df[interaction_df['ProviderCode'].isin(reco_lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceabfae2-2a5e-43f0-ae5f-5c37987b0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df=interaction_df[interaction_df['PERSON_ID']==user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ca470-56e9-4b43-9e29-9df4bd374092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
